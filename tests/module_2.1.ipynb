{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f34e219",
   "metadata": {},
   "source": [
    "Для создания симулятора энергопотребления необходимо определить математическую модель, которая учитывает два основных компонента: энергию на вычисления ($E_{comp}$) и энергию на перемещение данных ($E_{data}$).\n",
    "\n",
    "В нейроморфных и специализированных архитектурах (NPU) основной выигрыш достигается за счет минимизации $E_{data}$, так как перемещение данных из внешней памяти (DRAM) в процессор может потреблять в 100–1000 раз больше энергии, чем сама операция умножения.\n",
    "\n",
    "Общая энергия ($E_{total}$) для задачи умножения двух матриц размером $N \\times N$ рассчитывается как:\n",
    "\n",
    "$$E_{total} = E_{comp} + E_{data}$$\n",
    "\n",
    "Где:\n",
    "- Количество операций (FLOPs) для умножения матриц: $2 \\cdot N^3$.\n",
    "- Объем данных: $3 \\cdot N^2 \\cdot \\text{size\\_of\\_element}$ (две входные матрицы и одна выходная).\n",
    "\n",
    "| Архитектура | Энергия на операцию (e_op) | Энергия на перенос байта (e_byte) | Особенности |\n",
    "|------------|---------------------------|-----------------------------------|-------------|\n",
    "| GPU (H100/A100) | ~1.0 отн. ед. | Высокая (DRAM ↔ Core) | Огромная мощь, но высокая цена за перемещение данных. |\n",
    "| TPU (v5/v6) | ~0.5 отн. ед. | Средняя (HBM ↔ Systolic Array) | Систолические массивы минимизируют обращения к памяти внутри чипа. |\n",
    "| NPU (Edge/In-memory) | ~0.1 отн. ед. | Близка к 0 (Data-in-place) | Данные хранятся там же, где вычисляются (Compute-in-Memory). |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1204159a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Симуляция энергопотребления (Матрица 1024x1024)\n",
      "GPU: Вычисления=2.15e+10 пДж, Данные=1.26e+09 пДж, Всего=2.27e+10 пДж\n",
      "TPU: Вычисления=1.07e+10 пДж, Данные=3.77e+08 пДж, Всего=1.11e+10 пДж\n",
      "NPU: Вычисления=2.15e+09 пДж, Данные=2.52e+07 пДж, Всего=2.17e+09 пДж\n"
     ]
    }
   ],
   "source": [
    "class Architecture:\n",
    "    \"\"\"Базовый класс для вычислительных архитектур\"\"\"\n",
    "    def __init__(self, e_op, e_byte):\n",
    "        self.e_op = e_op      # Энергия на одну операцию (пДж)\n",
    "        self.e_byte = e_byte  # Энергия на перемещение 1 байта (пДж)\n",
    "\n",
    "    def calculate_energy(self, N):\n",
    "        \"\"\"Общий метод расчета для перемножения матриц NxN\"\"\"\n",
    "        ops = 2 * (N**3)\n",
    "        data_volume = 3 * (N**2) * 4  # 4 байта на float32\n",
    "        \n",
    "        e_comp = ops * self.e_op\n",
    "        e_data = data_volume * self.e_byte\n",
    "        return e_comp, e_data\n",
    "\n",
    "class GPU(Architecture):\n",
    "    def __init__(self):\n",
    "        super().__init__(e_op=10, e_byte=100)\n",
    "\n",
    "class TPU(Architecture):\n",
    "    def __init__(self):\n",
    "        super().__init__(e_op=5, e_byte=30)\n",
    "\n",
    "class NPU(Architecture):\n",
    "    def __init__(self):\n",
    "        super().__init__(e_op=1, e_byte=2)\n",
    "\n",
    "def run_simulation(N):\n",
    "    architectures = [GPU(), TPU(), NPU()]\n",
    "    \n",
    "    print(f\"Симуляция энергопотребления (Матрица {N}x{N})\")\n",
    "    for arch in architectures:\n",
    "        comp, data = arch.calculate_energy(N)\n",
    "        total = comp + data\n",
    "\n",
    "        name = arch.__class__.__name__\n",
    "        \n",
    "        print(f\"{name:3}: Вычисления={comp:.2e} пДж, Данные={data:.2e} пДж, Всего={total:.2e} пДж\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_simulation(1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aed2219",
   "metadata": {},
   "source": [
    "GPU: Затраты на данные составляют значительную часть бюджета.\n",
    "\n",
    "TPU уверенно занимает промежуточное положение. Его архитектура (систолические массивы) оптимизирована под умножение матриц лучше, чем у GPU, что позволило сократить расходы на данные почти в 3.3 раза по сравнению с графическим процессором.\n",
    "\n",
    "NPU показал себя в 10.5 раз эффективнее, чем GPU, и в 5 раз эффективнее, чем TPU. Итоговое потребление: $2.17 \\times 10^9$ пДж против $22.7 \\times 10^9$ пДж у GPU. Такой результат достигается за счет радикального снижения затрат как на сами вычисления ($e_{op}$), так и на минимизацию перемещения данных."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
